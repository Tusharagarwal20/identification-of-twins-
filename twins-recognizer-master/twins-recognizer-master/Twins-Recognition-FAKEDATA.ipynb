{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env LD_LIBRARY_PATH /usr/local/cuda-10.0/lib64/\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import keras as ks\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from notebook_utils import *\n",
    "from visualize_layer import *\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    " print(\"Default GPU Device: {}\".format(tf.test.gpu_device_name()))\n",
    "else:\n",
    " print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/benoitpatra/code/twins-recognizer/data/sets_faked'\n",
    "\n",
    "TRAIN_DIR = os.path.join(base_dir, 'train')\n",
    "VAL_DIR = os.path.join(base_dir, 'validation')\n",
    "TEST_DIR = os.path.join(base_dir, 'test')\n",
    "\n",
    "TARGET_SIZE = 200\n",
    "BATCH_SIZE = 10\n",
    "TRAIN_SET_SIZE=600\n",
    "steps_per_epoch= TRAIN_SET_SIZE // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define TRAINING SET\n",
    "train_datagen =  ImageDataGenerator(rescale=1./255, rotation_range=0,\n",
    "                              width_shift_range=0.2,\n",
    "                              height_shift_range=0.2,\n",
    "                              shear_range=0.2,\n",
    "                              zoom_range=0.2,\n",
    "                              horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAIN_DIR, \n",
    "                                                    target_size=(TARGET_SIZE, TARGET_SIZE), \n",
    "                                                    batch_size = BATCH_SIZE, \n",
    "                                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define VALIDATION SET\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(VAL_DIR, \n",
    "                                                    target_size=(TARGET_SIZE, TARGET_SIZE), \n",
    "                                                    batch_size = BATCH_SIZE, \n",
    "                                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index=7\n",
    "img = next(train_generator)\n",
    "print(img[0][img_index,:,:,:].shape)\n",
    "print_image_from_gen(img[0][img_index,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate_model(model):\n",
    "    t1 = time()\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-3), metrics=['acc'])\n",
    "    history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=30, validation_data=validation_generator, validation_steps=50)\n",
    "    t2 = time()\n",
    "    elapsed = t2 - t1\n",
    "    print('Elapsed time is %f seconds.' % elapsed)\n",
    "    plot_history2(model.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def model_dense():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, activation='relu', input_shape=(TARGET_SIZE,TARGET_SIZE, 3)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adhoc_convnet import *\n",
    "from VGG16_base import *\n",
    "\n",
    "#print(\"---NAIVE DENSE---\")\n",
    "#naive_dense = model_dense()\n",
    "#naive_dense.summary()\n",
    "\n",
    "print(\"---CONVENET---\")\n",
    "model_convenet_ad_hoc = adhoc_convnet(TARGET_SIZE)\n",
    "model_convenet_ad_hoc.summary()\n",
    "\n",
    "#print(\"---VGG16 BASE---\")\n",
    "#vgg_model = vgg16_base(TARGET_SIZE)\n",
    "#vgg_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"---EVALUATE NAIVE DENSE--\")\n",
    "train_and_validate_model(naive_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"---EVALUATE CONVNET ADHOC--\")\n",
    "#train_and_validate_model(model_convenet_ad_hoc)\n",
    "#model_convenet_ad_hoc.save_weights(\"model_convnet_20200421.h5\")\n",
    "print(\"---LOAD CONVNET ADHOC--\")\n",
    "model_convenet_ad_hoc.load_weights(\"model_convnet_20200421.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"---EVALUATE VGG BASE--\")\n",
    "#train_and_validate_model(vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: the shuffle=True is incompatible with building the Confusion matrix\n",
    "def get_test_generator():\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_generator = test_datagen.flow_from_directory(TEST_DIR, \n",
    "                                                        target_size=(TARGET_SIZE, TARGET_SIZE), \n",
    "                                                        batch_size = 1, \n",
    "                                                        shuffle = False,\n",
    "                                                        class_mode='binary')\n",
    "    return test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = get_test_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "TEST_SIZE=200\n",
    "target_names = ['J', 'L']\n",
    "Y_pred = model_convenet_ad_hoc.predict_generator(test_generator, TEST_SIZE)\n",
    "Y_pred = Y_pred.flatten()\n",
    "y_pred_class = np.where(Y_pred > 0.5, 1, 0)\n",
    "\n",
    "print('Classification Report')\n",
    "print(classification_report(test_generator.classes, y_pred_class, target_names=target_names))\n",
    "\n",
    "print('Confusion Matrix')\n",
    "plot_confusion_matrix(confusion_matrix(test_generator.classes, y_pred_class),target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next_skip(100, test_generator)\n",
    "print(\"Let use plot one prediction...\")\n",
    "view_prediction(model_convenet_ad_hoc, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATION_DEPTH=8\n",
    "activation_model = get_activation_model(model_convenet_ad_hoc, ACTIVATION_DEPTH)\n",
    "print(\"Print the activation model\")\n",
    "activation_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the activation tensors for a given layer_index and for a given channel\n",
    "visualize_on_tensor(model=model_convenet_ad_hoc, depth=ACTIVATION_DEPTH, layer_index=1, channel_index=21, img_tensor=batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize all intermediate layers\n",
    "visualize_layer(model=model_convenet_ad_hoc, depth=ACTIVATION_DEPTH, img_tensor=batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
